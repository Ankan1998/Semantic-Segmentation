{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "semantic_segmentation_model_simplified",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ankan1998/Semantic-Segmentation/blob/main/semantic_segmentation_model_simplified.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GQh4o9x72W6y",
        "outputId": "7e6afdc5-fa48-4e36-b57f-da3cc7cd4405",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "! git clone https://github.com/yassouali/pytorch_segmentation.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'pytorch_segmentation'...\n",
            "remote: Enumerating objects: 256, done.\u001b[K\n",
            "remote: Total 256 (delta 0), reused 0 (delta 0), pack-reused 256\u001b[K\n",
            "Receiving objects: 100% (256/256), 631.33 KiB | 19.13 MiB/s, done.\n",
            "Resolving deltas: 100% (138/138), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jGeDH3cK21kt",
        "outputId": "10cbcce3-7f43-448c-9287-f780bf036230",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!pip install -r /content/pytorch_segmentation/requirements.txt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting torch==1.1.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/69/60/f685fb2cfb3088736bafbc9bdbb455327bdc8906b606da9c9a81bae1c81e/torch-1.1.0-cp36-cp36m-manylinux1_x86_64.whl (676.9MB)\n",
            "\u001b[K     |████████████████████████████████| 676.9MB 26kB/s \n",
            "\u001b[?25hCollecting torchvision==0.3.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/2e/45/0f2f3062c92d9cf1d5d7eabd3cae88cea9affbd2b17fb1c043627838cb0a/torchvision-0.3.0-cp36-cp36m-manylinux1_x86_64.whl (2.6MB)\n",
            "\u001b[K     |████████████████████████████████| 2.6MB 51.8MB/s \n",
            "\u001b[?25hCollecting tqdm==4.32.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9f/3d/7a6b68b631d2ab54975f3a4863f3c4e9b26445353264ef01f465dc9b0208/tqdm-4.32.2-py2.py3-none-any.whl (50kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 7.7MB/s \n",
            "\u001b[?25hCollecting tensorboard==1.14.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/91/2d/2ed263449a078cd9c8a9ba50ebd50123adf1f8cfbea1492f9084169b89d9/tensorboard-1.14.0-py3-none-any.whl (3.1MB)\n",
            "\u001b[K     |████████████████████████████████| 3.2MB 59.6MB/s \n",
            "\u001b[?25hCollecting Pillow==6.2.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/19/66/6113477dc3206ccb1e192cffd626f2840ead02375a6cebe2436ad4c19f61/Pillow-6.2.0-cp36-cp36m-manylinux1_x86_64.whl (2.1MB)\n",
            "\u001b[K     |████████████████████████████████| 2.1MB 41.3MB/s \n",
            "\u001b[?25hCollecting opencv-python==4.1.0.25\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7b/d2/a2dbf83d4553ca6b3701d91d75e42fe50aea97acdc00652dca515749fb5d/opencv_python-4.1.0.25-cp36-cp36m-manylinux1_x86_64.whl (26.6MB)\n",
            "\u001b[K     |████████████████████████████████| 26.6MB 104kB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch==1.1.0->-r /content/pytorch_segmentation/requirements.txt (line 1)) (1.18.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision==0.3.0->-r /content/pytorch_segmentation/requirements.txt (line 2)) (1.15.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.6/dist-packages (from tensorboard==1.14.0->-r /content/pytorch_segmentation/requirements.txt (line 4)) (0.10.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard==1.14.0->-r /content/pytorch_segmentation/requirements.txt (line 4)) (50.3.0)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard==1.14.0->-r /content/pytorch_segmentation/requirements.txt (line 4)) (3.12.4)\n",
            "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorboard==1.14.0->-r /content/pytorch_segmentation/requirements.txt (line 4)) (0.35.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard==1.14.0->-r /content/pytorch_segmentation/requirements.txt (line 4)) (3.2.2)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard==1.14.0->-r /content/pytorch_segmentation/requirements.txt (line 4)) (1.0.1)\n",
            "Requirement already satisfied: grpcio>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard==1.14.0->-r /content/pytorch_segmentation/requirements.txt (line 4)) (1.32.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard==1.14.0->-r /content/pytorch_segmentation/requirements.txt (line 4)) (2.0.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard==1.14.0->-r /content/pytorch_segmentation/requirements.txt (line 4)) (3.2.0)\n",
            "\u001b[31mERROR: tensorflow 2.3.0 has requirement tensorboard<3,>=2.3.0, but you'll have tensorboard 1.14.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: spacy 2.2.4 has requirement tqdm<5.0.0,>=4.38.0, but you'll have tqdm 4.32.2 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: fbprophet 0.7.1 has requirement tqdm>=4.36.1, but you'll have tqdm 4.32.2 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Installing collected packages: torch, Pillow, torchvision, tqdm, tensorboard, opencv-python\n",
            "  Found existing installation: torch 1.6.0+cu101\n",
            "    Uninstalling torch-1.6.0+cu101:\n",
            "      Successfully uninstalled torch-1.6.0+cu101\n",
            "  Found existing installation: Pillow 7.0.0\n",
            "    Uninstalling Pillow-7.0.0:\n",
            "      Successfully uninstalled Pillow-7.0.0\n",
            "  Found existing installation: torchvision 0.7.0+cu101\n",
            "    Uninstalling torchvision-0.7.0+cu101:\n",
            "      Successfully uninstalled torchvision-0.7.0+cu101\n",
            "  Found existing installation: tqdm 4.41.1\n",
            "    Uninstalling tqdm-4.41.1:\n",
            "      Successfully uninstalled tqdm-4.41.1\n",
            "  Found existing installation: tensorboard 2.3.0\n",
            "    Uninstalling tensorboard-2.3.0:\n",
            "      Successfully uninstalled tensorboard-2.3.0\n",
            "  Found existing installation: opencv-python 4.1.2.30\n",
            "    Uninstalling opencv-python-4.1.2.30:\n",
            "      Successfully uninstalled opencv-python-4.1.2.30\n",
            "Successfully installed Pillow-6.2.0 opencv-python-4.1.0.25 tensorboard-1.14.0 torch-1.1.0 torchvision-0.3.0 tqdm-4.32.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "PIL"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ug0nWf5jlnwh"
      },
      "source": [
        "## **Common Imports for ALL MODELS**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0stZ08hCpUba"
      },
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchvision import models\n",
        "from torchsummary import summary\n",
        "from itertools import chain\n",
        "import logging"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YYzJffnIp7XS"
      },
      "source": [
        "## **Common Base Model Abstraction**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7RZculT73Bqy"
      },
      "source": [
        "class BaseModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(BaseModel, self).__init__()\n",
        "        self.logger = logging.getLogger(self.__class__.__name__)\n",
        "\n",
        "    def forward(self):\n",
        "        raise NotImplementedError\n",
        "\n",
        "    def summary(self):\n",
        "        model_parameters = filter(lambda p: p.requires_grad, self.parameters())\n",
        "        nbr_params = sum([np.prod(p.size()) for p in model_parameters])\n",
        "        self.logger.info(f'Nbr of trainable parameters: {nbr_params}')\n",
        "\n",
        "    def __str__(self):\n",
        "        model_parameters = filter(lambda p: p.requires_grad, self.parameters())\n",
        "        nbr_params = sum([np.prod(p.size()) for p in model_parameters])\n",
        "        return super(BaseModel, self).__str__() + f'\\nNbr of trainable parameters: {nbr_params}'\n",
        "        #return summary(self, input_shape=(2, 3, 224, 224))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JuvoVdtnqN8l"
      },
      "source": [
        "# **The below lines will contain different architecture simplified for beginners. They follow same pattern first base architecture then model summary**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kAwAOTU6qy0u"
      },
      "source": [
        "## **FCN Architecture** (semantic segmentation)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FN-1JbCjq-y6"
      },
      "source": [
        "def get_upsampling_weight(in_channels, out_channels, kernel_size):\n",
        "    factor = (kernel_size + 1) // 2\n",
        "    if kernel_size % 2 == 1:\n",
        "            center = factor - 1\n",
        "    else:\n",
        "            center = factor - 0.5\n",
        "    og = np.ogrid[:kernel_size, :kernel_size]\n",
        "    filt = (1 - abs(og[0] - center) / factor) * (1 - abs(og[1] - center) / factor)\n",
        "    weight = np.zeros((in_channels, out_channels, kernel_size, kernel_size), dtype=np.float64)\n",
        "    weight[list(range(in_channels)), list(range(out_channels)), :, :] = filt\n",
        "    return torch.from_numpy(weight).float()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qFFF7Doeq_Nm"
      },
      "source": [
        "# Need to be review and improved later\n",
        "class FCN8(BaseModel):\n",
        "    def __init__(self, num_classes, pretrained=True, freeze_bn=False, **_):\n",
        "        super(FCN8, self).__init__()\n",
        "        vgg = models.vgg16(pretrained)\n",
        "        features = list(vgg.features.children())\n",
        "        classifier = list(vgg.classifier.children())\n",
        "\n",
        "        # Pad the input to enable small inputs and allow matching feature maps\n",
        "        features[0].padding = (100, 100)\n",
        "\n",
        "        # Enbale ceil in max pool, to avoid different sizes when upsampling\n",
        "        for layer in features:\n",
        "            if 'MaxPool' in layer.__class__.__name__:\n",
        "                layer.ceil_mode = True\n",
        "\n",
        "        # Extract pool3, pool4 and pool5 from the VGG net\n",
        "        self.pool3 = nn.Sequential(*features[:17])\n",
        "        self.pool4 = nn.Sequential(*features[17:24])\n",
        "        self.pool5 = nn.Sequential(*features[24:])\n",
        "\n",
        "        # Adjust the depth of pool3 and pool4 to num_classes\n",
        "        self.adj_pool3 = nn.Conv2d(256, num_classes, kernel_size=1)\n",
        "        self.adj_pool4 = nn.Conv2d(512, num_classes, kernel_size=1)\n",
        "\n",
        "        # Replace the FC layer of VGG with conv layers\n",
        "        conv6 = nn.Conv2d(512, 4096, kernel_size=7)\n",
        "        conv7 = nn.Conv2d(4096, 4096, kernel_size=1)\n",
        "        output = nn.Conv2d(4096, num_classes, kernel_size=1)\n",
        "\n",
        "        # Copy the weights from VGG's FC pretrained layers\n",
        "        conv6.weight.data.copy_(classifier[0].weight.data.view(\n",
        "            conv6.weight.data.size()))\n",
        "        conv6.bias.data.copy_(classifier[0].bias.data)\n",
        "        \n",
        "        conv7.weight.data.copy_(classifier[3].weight.data.view(\n",
        "            conv7.weight.data.size()))\n",
        "        conv7.bias.data.copy_(classifier[3].bias.data)\n",
        "        \n",
        "        # Get the outputs\n",
        "        self.output = nn.Sequential(conv6, nn.ReLU(inplace=True), nn.Dropout(),\n",
        "                                    conv7, nn.ReLU(inplace=True), nn.Dropout(), \n",
        "                                    output)\n",
        "\n",
        "        # We'll need three upsampling layers, upsampling (x2 +2) the ouputs\n",
        "        # upsampling (x2 +2) addition of pool4 and upsampled output \n",
        "        # upsampling (x8 +8) the final value (pool3 + added output and pool4)\n",
        "        self.up_output = nn.ConvTranspose2d(num_classes, num_classes,\n",
        "                                            kernel_size=4, stride=2, bias=False)\n",
        "        self.up_pool4_out = nn.ConvTranspose2d(num_classes, num_classes, \n",
        "                                            kernel_size=4, stride=2, bias=False)\n",
        "        self.up_final = nn.ConvTranspose2d(num_classes, num_classes, \n",
        "                                            kernel_size=16, stride=8, bias=False)\n",
        "\n",
        "        # We'll use guassian kernels for the upsampling weights\n",
        "        self.up_output.weight.data.copy_(\n",
        "            get_upsampling_weight(num_classes, num_classes, 4))\n",
        "        self.up_pool4_out.weight.data.copy_(\n",
        "            get_upsampling_weight(num_classes, num_classes, 4))\n",
        "        self.up_final.weight.data.copy_(\n",
        "            get_upsampling_weight(num_classes, num_classes, 16))\n",
        "\n",
        "        # We'll freeze the wights, this is a fixed upsampling and not deconv\n",
        "        \"\"\"\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.ConvTranspose2d):\n",
        "                m.weight.requires_grad = False\n",
        "        if freeze_bn: self.freeze_bn()\n",
        "        if freeze_backbone: \n",
        "            set_trainable([self.pool3, self.pool4, self.pool5], False)\n",
        "        \"\"\"\n",
        "\n",
        "    def forward(self, x):\n",
        "        imh_H, img_W = x.size()[2], x.size()[3]\n",
        "        \n",
        "        # Forward the image\n",
        "        pool3 = self.pool3(x)\n",
        "        pool4 = self.pool4(pool3)\n",
        "        pool5 = self.pool5(pool4)\n",
        "\n",
        "        # Get the outputs and upsmaple them\n",
        "        output = self.output(pool5)\n",
        "        up_output = self.up_output(output)\n",
        "\n",
        "        # Adjust pool4 and add the uped-outputs to pool4\n",
        "        adjstd_pool4 = self.adj_pool4(0.01 * pool4)\n",
        "        add_out_pool4 = self.up_pool4_out(adjstd_pool4[:, :, 5: (5 + up_output.size()[2]), \n",
        "                                            5: (5 + up_output.size()[3])]\n",
        "                                           + up_output)\n",
        "\n",
        "        # Adjust pool3 and add it to the uped last addition\n",
        "        adjstd_pool3 = self.adj_pool3(0.0001 * pool3)\n",
        "        final_value = self.up_final(adjstd_pool3[:, :, 9: (9 + add_out_pool4.size()[2]), 9: (9 + add_out_pool4.size()[3])]\n",
        "                                 + add_out_pool4)\n",
        "\n",
        "        # Remove the corresponding padded regions to the input img size\n",
        "        final_value = final_value[:, :, 31: (31 + imh_H), 31: (31 + img_W)].contiguous()\n",
        "        return final_value\n",
        "\n",
        "    def get_backbone_params(self):\n",
        "        return chain(self.pool3.parameters(), self.pool4.parameters(), self.pool5.parameters(), self.output.parameters())\n",
        "\n",
        "    def get_decoder_params(self):\n",
        "        return chain(self.up_output.parameters(), self.adj_pool4.parameters(), self.up_pool4_out.parameters(),\n",
        "            self.adj_pool3.parameters(), self.up_final.parameters())\n",
        "\n",
        "    def freeze_bn(self):\n",
        "        for module in self.modules():\n",
        "            if isinstance(module, nn.BatchNorm2d): module.eval()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lUtmlTkAq-4v"
      },
      "source": [
        "model1=FCN8(num_classes=22)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oOroMr8dq-v2",
        "outputId": "4817cc19-f7c6-40d9-d2bc-5f870ec3a974",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(model1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "FCN8(\n",
            "  (pool3): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(100, 100))\n",
            "    (1): ReLU(inplace)\n",
            "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (3): ReLU(inplace)\n",
            "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
            "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (6): ReLU(inplace)\n",
            "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): ReLU(inplace)\n",
            "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
            "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): ReLU(inplace)\n",
            "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (13): ReLU(inplace)\n",
            "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): ReLU(inplace)\n",
            "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
            "  )\n",
            "  (pool4): Sequential(\n",
            "    (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): ReLU(inplace)\n",
            "    (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (3): ReLU(inplace)\n",
            "    (4): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (5): ReLU(inplace)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
            "  )\n",
            "  (pool5): Sequential(\n",
            "    (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): ReLU(inplace)\n",
            "    (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (3): ReLU(inplace)\n",
            "    (4): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (5): ReLU(inplace)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
            "  )\n",
            "  (adj_pool3): Conv2d(256, 22, kernel_size=(1, 1), stride=(1, 1))\n",
            "  (adj_pool4): Conv2d(512, 22, kernel_size=(1, 1), stride=(1, 1))\n",
            "  (output): Sequential(\n",
            "    (0): Conv2d(512, 4096, kernel_size=(7, 7), stride=(1, 1))\n",
            "    (1): ReLU(inplace)\n",
            "    (2): Dropout(p=0.5)\n",
            "    (3): Conv2d(4096, 4096, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (4): ReLU(inplace)\n",
            "    (5): Dropout(p=0.5)\n",
            "    (6): Conv2d(4096, 22, kernel_size=(1, 1), stride=(1, 1))\n",
            "  )\n",
            "  (up_output): ConvTranspose2d(22, 22, kernel_size=(4, 4), stride=(2, 2), bias=False)\n",
            "  (up_pool4_out): ConvTranspose2d(22, 22, kernel_size=(4, 4), stride=(2, 2), bias=False)\n",
            "  (up_final): ConvTranspose2d(22, 22, kernel_size=(16, 16), stride=(8, 8), bias=False)\n",
            ")\n",
            "Nbr of trainable parameters: 134507010\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SfrJ6ewSq-t_"
      },
      "source": [
        "model1=model1.to('cuda')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4yGQSqynwBJL",
        "outputId": "cc6c4f1b-b732-4687-be3c-c0c08cd8944b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "summary(model1,(3,256,256))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1         [-1, 64, 454, 454]           1,792\n",
            "              ReLU-2         [-1, 64, 454, 454]               0\n",
            "            Conv2d-3         [-1, 64, 454, 454]          36,928\n",
            "              ReLU-4         [-1, 64, 454, 454]               0\n",
            "         MaxPool2d-5         [-1, 64, 227, 227]               0\n",
            "            Conv2d-6        [-1, 128, 227, 227]          73,856\n",
            "              ReLU-7        [-1, 128, 227, 227]               0\n",
            "            Conv2d-8        [-1, 128, 227, 227]         147,584\n",
            "              ReLU-9        [-1, 128, 227, 227]               0\n",
            "        MaxPool2d-10        [-1, 128, 114, 114]               0\n",
            "           Conv2d-11        [-1, 256, 114, 114]         295,168\n",
            "             ReLU-12        [-1, 256, 114, 114]               0\n",
            "           Conv2d-13        [-1, 256, 114, 114]         590,080\n",
            "             ReLU-14        [-1, 256, 114, 114]               0\n",
            "           Conv2d-15        [-1, 256, 114, 114]         590,080\n",
            "             ReLU-16        [-1, 256, 114, 114]               0\n",
            "        MaxPool2d-17          [-1, 256, 57, 57]               0\n",
            "           Conv2d-18          [-1, 512, 57, 57]       1,180,160\n",
            "             ReLU-19          [-1, 512, 57, 57]               0\n",
            "           Conv2d-20          [-1, 512, 57, 57]       2,359,808\n",
            "             ReLU-21          [-1, 512, 57, 57]               0\n",
            "           Conv2d-22          [-1, 512, 57, 57]       2,359,808\n",
            "             ReLU-23          [-1, 512, 57, 57]               0\n",
            "        MaxPool2d-24          [-1, 512, 29, 29]               0\n",
            "           Conv2d-25          [-1, 512, 29, 29]       2,359,808\n",
            "             ReLU-26          [-1, 512, 29, 29]               0\n",
            "           Conv2d-27          [-1, 512, 29, 29]       2,359,808\n",
            "             ReLU-28          [-1, 512, 29, 29]               0\n",
            "           Conv2d-29          [-1, 512, 29, 29]       2,359,808\n",
            "             ReLU-30          [-1, 512, 29, 29]               0\n",
            "        MaxPool2d-31          [-1, 512, 15, 15]               0\n",
            "           Conv2d-32           [-1, 4096, 9, 9]     102,764,544\n",
            "             ReLU-33           [-1, 4096, 9, 9]               0\n",
            "          Dropout-34           [-1, 4096, 9, 9]               0\n",
            "           Conv2d-35           [-1, 4096, 9, 9]      16,781,312\n",
            "             ReLU-36           [-1, 4096, 9, 9]               0\n",
            "          Dropout-37           [-1, 4096, 9, 9]               0\n",
            "           Conv2d-38             [-1, 22, 9, 9]          90,134\n",
            "  ConvTranspose2d-39           [-1, 22, 20, 20]           7,744\n",
            "           Conv2d-40           [-1, 22, 29, 29]          11,286\n",
            "  ConvTranspose2d-41           [-1, 22, 42, 42]           7,744\n",
            "           Conv2d-42           [-1, 22, 57, 57]           5,654\n",
            "  ConvTranspose2d-43         [-1, 22, 344, 344]         123,904\n",
            "================================================================\n",
            "Total params: 134,507,010\n",
            "Trainable params: 134,507,010\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.75\n",
            "Forward/backward pass size (MB): 936.49\n",
            "Params size (MB): 513.10\n",
            "Estimated Total Size (MB): 1450.34\n",
            "----------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CDHrXK16kkdk"
      },
      "source": [
        "## **U-Net Architecture**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MXLr2dyzkhOO"
      },
      "source": [
        "class encoder(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(encoder, self).__init__()\n",
        "        self.down_conv = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "        )\n",
        "        self.pool = nn.MaxPool2d(kernel_size=2, ceil_mode=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.down_conv(x)\n",
        "        x_pooled = self.pool(x)\n",
        "        return x, x_pooled\n",
        "\n",
        "class decoder(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(decoder, self).__init__()\n",
        "        self.up = nn.ConvTranspose2d(in_channels, out_channels, kernel_size=2, stride=2)\n",
        "        self.up_conv = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "        )\n",
        "\n",
        "    def forward(self, x_copy, x, interpolate=True):\n",
        "        x = self.up(x)\n",
        "        if interpolate:\n",
        "            # Iterpolating instead of padding gives better results\n",
        "            x = F.interpolate(x, size=(x_copy.size(2), x_copy.size(3)),\n",
        "                              mode=\"bilinear\", align_corners=True)\n",
        "        else:\n",
        "            # Padding in case the incomping volumes are of different sizes\n",
        "            diffY = x_copy.size()[2] - x.size()[2]\n",
        "            diffX = x_copy.size()[3] - x.size()[3]\n",
        "            x = F.pad(x, (diffX // 2, diffX - diffX // 2,\n",
        "                            diffY // 2, diffY - diffY // 2))\n",
        "        # Concatenate\n",
        "        x = torch.cat([x_copy, x], dim=1)\n",
        "        x = self.up_conv(x)\n",
        "        return x\n",
        "\n",
        "class UNet(BaseModel):\n",
        "    def __init__(self, num_classes, in_channels=3, freeze_bn=False, **_):\n",
        "        super(UNet, self).__init__()\n",
        "        self.down1 = encoder(in_channels, 64)\n",
        "        self.down2 = encoder(64, 128)\n",
        "        self.down3 = encoder(128, 256)\n",
        "        self.down4 = encoder(256, 512)\n",
        "        self.middle_conv = nn.Sequential(\n",
        "            nn.Conv2d(512, 1024, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(1024),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(1024, 1024, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(1024),\n",
        "            nn.ReLU(inplace=True),\n",
        "        )\n",
        "        self.up1 = decoder(1024, 512)\n",
        "        self.up2 = decoder(512, 256)\n",
        "        self.up3 = decoder(256, 128)\n",
        "        self.up4 = decoder(128, 64)\n",
        "        self.final_conv = nn.Conv2d(64, num_classes, kernel_size=1)\n",
        "        self._initialize_weights()\n",
        "        if freeze_bn: self.freeze_bn()\n",
        "\n",
        "    def _initialize_weights(self):\n",
        "        for module in self.modules():\n",
        "            if isinstance(module, nn.Conv2d) or isinstance(module, nn.Linear):\n",
        "                nn.init.kaiming_normal_(module.weight)\n",
        "                if module.bias is not None:\n",
        "                    module.bias.data.zero_()\n",
        "            elif isinstance(module, nn.BatchNorm2d):\n",
        "                module.weight.data.fill_(1)\n",
        "                module.bias.data.zero_()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x1, x = self.down1(x)\n",
        "        x2, x = self.down2(x)\n",
        "        x3, x = self.down3(x)\n",
        "        x4, x = self.down4(x)\n",
        "        x = self.middle_conv(x)\n",
        "        x = self.up1(x4, x)\n",
        "        x = self.up2(x3, x)\n",
        "        x = self.up3(x2, x)\n",
        "        x = self.up4(x1, x)\n",
        "        x = self.final_conv(x)\n",
        "        return x\n",
        "\n",
        "    def get_backbone_params(self):\n",
        "        # There is no backbone for unet, all the parameters are trained from scratch\n",
        "        return []\n",
        "\n",
        "    def get_decoder_params(self):\n",
        "        return self.parameters()\n",
        "\n",
        "    def freeze_bn(self):\n",
        "        for module in self.modules():\n",
        "            if isinstance(module, nn.BatchNorm2d): module.eval()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T6S8bTzA5fmg"
      },
      "source": [
        "model2= UNet(num_classes=22)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "blJ1FmQw5ytH",
        "outputId": "07b805cb-75de-4495-e8e3-0ad29bc81b86",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(model2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "UNet(\n",
            "  (down1): encoder(\n",
            "    (down_conv): Sequential(\n",
            "      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): ReLU(inplace)\n",
            "      (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (5): ReLU(inplace)\n",
            "    )\n",
            "    (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
            "  )\n",
            "  (down2): encoder(\n",
            "    (down_conv): Sequential(\n",
            "      (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): ReLU(inplace)\n",
            "      (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (5): ReLU(inplace)\n",
            "    )\n",
            "    (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
            "  )\n",
            "  (down3): encoder(\n",
            "    (down_conv): Sequential(\n",
            "      (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): ReLU(inplace)\n",
            "      (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (5): ReLU(inplace)\n",
            "    )\n",
            "    (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
            "  )\n",
            "  (down4): encoder(\n",
            "    (down_conv): Sequential(\n",
            "      (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): ReLU(inplace)\n",
            "      (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (5): ReLU(inplace)\n",
            "    )\n",
            "    (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
            "  )\n",
            "  (middle_conv): Sequential(\n",
            "    (0): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace)\n",
            "    (3): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace)\n",
            "  )\n",
            "  (up1): decoder(\n",
            "    (up): ConvTranspose2d(1024, 512, kernel_size=(2, 2), stride=(2, 2))\n",
            "    (up_conv): Sequential(\n",
            "      (0): Conv2d(1024, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): ReLU(inplace)\n",
            "      (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (5): ReLU(inplace)\n",
            "    )\n",
            "  )\n",
            "  (up2): decoder(\n",
            "    (up): ConvTranspose2d(512, 256, kernel_size=(2, 2), stride=(2, 2))\n",
            "    (up_conv): Sequential(\n",
            "      (0): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): ReLU(inplace)\n",
            "      (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (5): ReLU(inplace)\n",
            "    )\n",
            "  )\n",
            "  (up3): decoder(\n",
            "    (up): ConvTranspose2d(256, 128, kernel_size=(2, 2), stride=(2, 2))\n",
            "    (up_conv): Sequential(\n",
            "      (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): ReLU(inplace)\n",
            "      (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (5): ReLU(inplace)\n",
            "    )\n",
            "  )\n",
            "  (up4): decoder(\n",
            "    (up): ConvTranspose2d(128, 64, kernel_size=(2, 2), stride=(2, 2))\n",
            "    (up_conv): Sequential(\n",
            "      (0): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): ReLU(inplace)\n",
            "      (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (5): ReLU(inplace)\n",
            "    )\n",
            "  )\n",
            "  (final_conv): Conv2d(64, 22, kernel_size=(1, 1), stride=(1, 1))\n",
            ")\n",
            "Nbr of trainable parameters: 31044886\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rcVRQQr2ipzr"
      },
      "source": [
        "model2=model2.to('cuda')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z7m4mheJgijI",
        "outputId": "da50c201-84af-4e4d-80dd-7ad3f8f95b30",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "summary(model2,(3,256,256))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1         [-1, 64, 256, 256]           1,792\n",
            "       BatchNorm2d-2         [-1, 64, 256, 256]             128\n",
            "              ReLU-3         [-1, 64, 256, 256]               0\n",
            "            Conv2d-4         [-1, 64, 256, 256]          36,928\n",
            "       BatchNorm2d-5         [-1, 64, 256, 256]             128\n",
            "              ReLU-6         [-1, 64, 256, 256]               0\n",
            "         MaxPool2d-7         [-1, 64, 128, 128]               0\n",
            "           encoder-8  [[-1, 64, 256, 256], [-1, 64, 128, 128]]               0\n",
            "            Conv2d-9        [-1, 128, 128, 128]          73,856\n",
            "      BatchNorm2d-10        [-1, 128, 128, 128]             256\n",
            "             ReLU-11        [-1, 128, 128, 128]               0\n",
            "           Conv2d-12        [-1, 128, 128, 128]         147,584\n",
            "      BatchNorm2d-13        [-1, 128, 128, 128]             256\n",
            "             ReLU-14        [-1, 128, 128, 128]               0\n",
            "        MaxPool2d-15          [-1, 128, 64, 64]               0\n",
            "          encoder-16  [[-1, 128, 128, 128], [-1, 128, 64, 64]]               0\n",
            "           Conv2d-17          [-1, 256, 64, 64]         295,168\n",
            "      BatchNorm2d-18          [-1, 256, 64, 64]             512\n",
            "             ReLU-19          [-1, 256, 64, 64]               0\n",
            "           Conv2d-20          [-1, 256, 64, 64]         590,080\n",
            "      BatchNorm2d-21          [-1, 256, 64, 64]             512\n",
            "             ReLU-22          [-1, 256, 64, 64]               0\n",
            "        MaxPool2d-23          [-1, 256, 32, 32]               0\n",
            "          encoder-24  [[-1, 256, 64, 64], [-1, 256, 32, 32]]               0\n",
            "           Conv2d-25          [-1, 512, 32, 32]       1,180,160\n",
            "      BatchNorm2d-26          [-1, 512, 32, 32]           1,024\n",
            "             ReLU-27          [-1, 512, 32, 32]               0\n",
            "           Conv2d-28          [-1, 512, 32, 32]       2,359,808\n",
            "      BatchNorm2d-29          [-1, 512, 32, 32]           1,024\n",
            "             ReLU-30          [-1, 512, 32, 32]               0\n",
            "        MaxPool2d-31          [-1, 512, 16, 16]               0\n",
            "          encoder-32  [[-1, 512, 32, 32], [-1, 512, 16, 16]]               0\n",
            "           Conv2d-33         [-1, 1024, 16, 16]       4,719,616\n",
            "      BatchNorm2d-34         [-1, 1024, 16, 16]           2,048\n",
            "             ReLU-35         [-1, 1024, 16, 16]               0\n",
            "           Conv2d-36         [-1, 1024, 16, 16]       9,438,208\n",
            "      BatchNorm2d-37         [-1, 1024, 16, 16]           2,048\n",
            "             ReLU-38         [-1, 1024, 16, 16]               0\n",
            "  ConvTranspose2d-39          [-1, 512, 32, 32]       2,097,664\n",
            "           Conv2d-40          [-1, 512, 32, 32]       4,719,104\n",
            "      BatchNorm2d-41          [-1, 512, 32, 32]           1,024\n",
            "             ReLU-42          [-1, 512, 32, 32]               0\n",
            "           Conv2d-43          [-1, 512, 32, 32]       2,359,808\n",
            "      BatchNorm2d-44          [-1, 512, 32, 32]           1,024\n",
            "             ReLU-45          [-1, 512, 32, 32]               0\n",
            "          decoder-46          [-1, 512, 32, 32]               0\n",
            "  ConvTranspose2d-47          [-1, 256, 64, 64]         524,544\n",
            "           Conv2d-48          [-1, 256, 64, 64]       1,179,904\n",
            "      BatchNorm2d-49          [-1, 256, 64, 64]             512\n",
            "             ReLU-50          [-1, 256, 64, 64]               0\n",
            "           Conv2d-51          [-1, 256, 64, 64]         590,080\n",
            "      BatchNorm2d-52          [-1, 256, 64, 64]             512\n",
            "             ReLU-53          [-1, 256, 64, 64]               0\n",
            "          decoder-54          [-1, 256, 64, 64]               0\n",
            "  ConvTranspose2d-55        [-1, 128, 128, 128]         131,200\n",
            "           Conv2d-56        [-1, 128, 128, 128]         295,040\n",
            "      BatchNorm2d-57        [-1, 128, 128, 128]             256\n",
            "             ReLU-58        [-1, 128, 128, 128]               0\n",
            "           Conv2d-59        [-1, 128, 128, 128]         147,584\n",
            "      BatchNorm2d-60        [-1, 128, 128, 128]             256\n",
            "             ReLU-61        [-1, 128, 128, 128]               0\n",
            "          decoder-62        [-1, 128, 128, 128]               0\n",
            "  ConvTranspose2d-63         [-1, 64, 256, 256]          32,832\n",
            "           Conv2d-64         [-1, 64, 256, 256]          73,792\n",
            "      BatchNorm2d-65         [-1, 64, 256, 256]             128\n",
            "             ReLU-66         [-1, 64, 256, 256]               0\n",
            "           Conv2d-67         [-1, 64, 256, 256]          36,928\n",
            "      BatchNorm2d-68         [-1, 64, 256, 256]             128\n",
            "             ReLU-69         [-1, 64, 256, 256]               0\n",
            "          decoder-70         [-1, 64, 256, 256]               0\n",
            "           Conv2d-71         [-1, 22, 256, 256]           1,430\n",
            "================================================================\n",
            "Total params: 31,044,886\n",
            "Trainable params: 31,044,886\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.75\n",
            "Forward/backward pass size (MB): 44563602.00\n",
            "Params size (MB): 118.43\n",
            "Estimated Total Size (MB): 44563721.18\n",
            "----------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ky_C6jB651JI",
        "outputId": "d2f3e3a2-47ba-4966-8b04-c94918ddfc84",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "for param in model.parameters():\n",
        "  print(type(param[0]))\n",
        "  break"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'torch.Tensor'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WPz4wAzWgnP4"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}